<!DOCTYPE html><html lang="zh-CN"><head><meta name="baidu-site-verification" content="h7QqekqYfg"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Every man is the master of his own fortune."><meta name="keywords" content="hayes"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><title>Transformer in Convolutional Neural Networks论文阅读笔记 | 海因斯的部落格</title><meta name="generator" content="Hexo 5.4.2"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Transformer in Convolutional Neural Networks论文阅读笔记</h1><a id="logo" href="/.">海因斯的部落格</a><p class="description">做颗星星，有棱有角，还会发光。</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Transformer in Convolutional Neural Networks论文阅读笔记</h1><div class="post-meta"><a href="/posts/9756efb3.html#comments" class="comment-count"></a><p><span class="date">Apr 23, 2022</span><span><a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" class="category">论文阅读</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h3 id="1-文献出处"><a href="#1-文献出处" class="headerlink" title="1.文献出处"></a>1.文献出处</h3><p>文献名：<em>Transformer in Convolutional Neural Networks</em></p>
<p>论文地址:<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.03180">https://arxiv.org/abs/2106.03180</a> </p>
<p>代码地址：<a target="_blank" rel="noopener" href="https://github.com/yun-liu/TransCNN">https://github.com/yun-liu/TransCNN</a></p>
</br>

<h3 id="2-文献研究内容"><a href="#2-文献研究内容" class="headerlink" title="2.文献研究内容"></a>2.文献研究内容</h3><p>针对多头自注意力模块（Multi-Head Self-Attention, MHSA）中计算和空间复杂度过高导致Vision Transformer效率低下的缺陷，提出一种层级多头注意力机制模块（Hierarchical Multi-Head Self-Attention, H-MHSA)，最后搭建而成的模型被称为TransCNN。</p>
</br>

<h3 id="3-研究创新点"><a href="#3-研究创新点" class="headerlink" title="3.研究创新点"></a>3.研究创新点</h3><ul>
<li><p>提出了层级多头注意力机制模块（MHSA)来使得Transformer中的自注意力机制计算得更加灵活和高效。</p>
</li>
<li><p>不再计算所有tokens的注意力，而是将patches进一步分组到小网格(grids)中，并计算每个网格中的注意力。这一步捕捉了局部关系，并产生了更具辨别力的局部表示。然后将这些小网格合并成更大的网格，并通过将前一步中的小网格视为标记来计算每个新网格中的注意力。通过这种方式，模型基本上捕获了更大区域中的特征关系。该过程被迭代以逐渐减少tokens的数量。</p>
</li>
<li><p>在整个过程中，H-MHSA模块逐步计算不断增加的区域大小中的自注意力，并自然地以分层方式对全局关系进行建模。 由于每一步的每个网格只有少量的tokens，可以显着降低视觉变换器的计算&#x2F;空间复杂度。</p>
</li>
<li><p>与之前对序列数据进行操作的Transformer网络不同，TransCNN 直接处理 3D 特征图，因此与过去十年提出的先进 CNN 技术兼容。 TransCNN 本质上继承了 CNN 和Transformer的优点，因此在学习尺度&#x2F;移位不变的特征表示和对输入数据中的长期依赖建模方面表现良好。</p>
</br></li>
</ul>
<h3 id="4-研究思路与方法"><a href="#4-研究思路与方法" class="headerlink" title="4.研究思路与方法"></a>4.研究思路与方法</h3><p><img src="https://s3.bmp.ovh/imgs/2022/04/23/9104476ebb0d9010.png"></p>
<p>提出的TransCNN模型是由层级多头注意力机制模块（H-MHSA)、反向残差瓶颈模块（IRB)和双分支下采样模块（TDB)共同组成的，H-MHSA模块和IRB模块用于获得输入图像得局部与全局特征，TDB模块用于降低特征图的大小。这三个模块可以共同组成一个完整的特征提取网络。</p>
<p>H-MHSA模块、IRB模块和TDB模块的代码实现部分如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#H-MHSA模块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, head_dim, grid_size=<span class="number">1</span>, ds_ratio=<span class="number">1</span>, drop=<span class="number">0.</span>, norm_layer=nn.BatchNorm2d</span>):</span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> dim % head_dim == <span class="number">0</span></span><br><span class="line">        self.num_heads = dim // head_dim</span><br><span class="line">        self.head_dim = head_dim</span><br><span class="line">        self.scale = self.head_dim ** -<span class="number">0.5</span></span><br><span class="line">        self.grid_size = grid_size</span><br><span class="line"></span><br><span class="line">        self.norm = norm_layer(dim)</span><br><span class="line">        self.qkv = nn.Conv2d(dim, dim * <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        self.proj = nn.Conv2d(dim, dim, <span class="number">1</span>)</span><br><span class="line">        self.drop = nn.Dropout2d(drop, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> grid_size &gt; <span class="number">1</span>:</span><br><span class="line">            self.grid_norm = norm_layer(dim)</span><br><span class="line">            self.avg_pool = nn.AvgPool2d(ds_ratio, stride=ds_ratio)</span><br><span class="line">            self.ds_norm = norm_layer(dim)</span><br><span class="line">            self.q = nn.Conv2d(dim, dim, <span class="number">1</span>)</span><br><span class="line">            self.kv = nn.Conv2d(dim, dim * <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        qkv = self.qkv(self.norm(x))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.grid_size &gt; <span class="number">1</span>:</span><br><span class="line">            grid_h, grid_w = H // self.grid_size, W // self.grid_size</span><br><span class="line">            qkv = qkv.reshape(B, <span class="number">3</span>, self.num_heads, self.head_dim, grid_h, self.grid_size, grid_w, self.grid_size)</span><br><span class="line">            qkv = qkv.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">3</span>)</span><br><span class="line">            qkv = qkv.reshape(<span class="number">3</span>, -<span class="number">1</span>, self.grid_size * self.grid_size, self.head_dim)</span><br><span class="line">            q, k, v = qkv[<span class="number">0</span>], qkv[<span class="number">1</span>], qkv[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">            attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * self.scale</span><br><span class="line">            attn = attn.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">            grid_x = (attn @ v).reshape(B, self.num_heads, grid_h, grid_w, self.grid_size, self.grid_size, self.head_dim)</span><br><span class="line">            grid_x = grid_x.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">5</span>).reshape(B, C, H, W)</span><br><span class="line">            grid_x = self.grid_norm(x + grid_x)</span><br><span class="line"></span><br><span class="line">            q = self.q(grid_x).reshape(B, self.num_heads, self.head_dim, -<span class="number">1</span>)</span><br><span class="line">            q = q.transpose(-<span class="number">2</span>, -<span class="number">1</span>)</span><br><span class="line">            kv = self.kv(self.ds_norm(self.avg_pool(grid_x)))</span><br><span class="line">            kv = self.reshape(B, <span class="number">2</span>, self.num_heads, self.head_dim, -<span class="number">1</span>)</span><br><span class="line">            kv = kv.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">            k, v = kv[<span class="number">0</span>], kv[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            qkv = qkv.reshape(B, <span class="number">3</span>, self.num_heads, self.head_dim, -<span class="number">1</span>)</span><br><span class="line">            qkv = qkv.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">            q, k, v = qkv[<span class="number">0</span>], qkv[<span class="number">1</span>], qkv[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        attn = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * self.scale</span><br><span class="line">        attn = attn.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">        global_x = (attn @ v).transpose(-<span class="number">2</span>, -<span class="number">1</span>).reshape(B, C, H, W)</span><br><span class="line">        <span class="keyword">if</span> self.grid_size &gt; <span class="number">1</span>:</span><br><span class="line">            global_x = global_x + grid_x</span><br><span class="line">        x = self.drop(self.proj(global_x))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">      </span><br><span class="line"><span class="comment"># IRB模块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InvertedResidual</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, hidden_dim=<span class="literal">None</span>, out_dim=<span class="literal">None</span>, kernel_size=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 drop=<span class="number">0.</span>, act_layer=nn.SiLU, norm_layer=nn.BatchNorm2d</span>):</span><br><span class="line">        <span class="built_in">super</span>(InvertedResidual, self).__init__()</span><br><span class="line">        hidden_dim = hidden_dim <span class="keyword">or</span> in_dim</span><br><span class="line">        out_dim = out_dim <span class="keyword">or</span> in_dim</span><br><span class="line">        pad = (kernel_size - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_dim, hidden_dim, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            norm_layer(hidden_dim),</span><br><span class="line">            act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, padding=pad, groups=hidden_dim, bias=<span class="literal">False</span>),</span><br><span class="line">            norm_layer(hidden_dim),</span><br><span class="line">            act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        self.conv3 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(hidden_dim, out_dim, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            norm_layer(out_dim)</span><br><span class="line">        )</span><br><span class="line">        self.drop = nn.Dropout2d(drop, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将二者进行组合的模块</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, head_dim, grid_size=<span class="number">1</span>, ds_ratio=<span class="number">1</span>, expansion=<span class="number">4</span>,</span></span><br><span class="line"><span class="params">                 drop=<span class="number">0.</span>, drop_path=<span class="number">0.</span>, kernel_size=<span class="number">3</span>, act_layer=nn.SiLU,</span></span><br><span class="line"><span class="params">                 norm_layer=nn.BatchNorm2d</span>):</span><br><span class="line">        <span class="built_in">super</span>(Block, self).__init__()</span><br><span class="line">        self.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        self.attn = Attention(dim, head_dim, grid_size=grid_size, ds_ratio=ds_ratio,</span><br><span class="line">            drop=drop, norm_layer=norm_layer)</span><br><span class="line">        self.conv = InvertedResidual(dim, hidden_dim=dim * expansion, out_dim=dim,</span><br><span class="line">            kernel_size=kernel_size, drop=drop, act_layer=act_layer, norm_layer=norm_layer)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + self.drop_path(self.attn(x))</span><br><span class="line">        x = x + self.drop_path(self.conv(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>最后是TDB下采样模块。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Downsample</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, out_dim, act_layer=nn.SiLU, norm_layer=nn.BatchNorm2d</span>):</span><br><span class="line">        <span class="built_in">super</span>(Downsample).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_dim, out_dim, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.residual = nn.Conv2d(in_dim, out_dim, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.norm1 = norm_layer(out_dim)</span><br><span class="line">        self.norm2 = norm_layer(out_dim)</span><br><span class="line">        self.act = act_layer(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x1 = self.norm1(self.conv(x))</span><br><span class="line">        x2 = self.norm2(self.residual(self.pool(x)))</span><br><span class="line">        x = self.act(x1 + x2)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

</br>

<p>TransCNN模型设计了两种网络结构，两种结构只在模块堆叠的数量上由区别，整体的参数表如下图所示：</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/LfywTO"><img src="https://s1.ax1x.com/2022/04/23/LfywTO.png" alt="LfywTO.png"></a></p>
<p>其中<code>C</code>表示通道数，<code>S</code>表示步长，<code>K</code>表示卷积核的大小，<code>E</code>表示IRB模块中的扩展率。在完整的TransCNN网络中，会先使用两个卷积对输入的图像进行降维，获得1&#x2F;4×1&#x2F;4大小的特征图进行后续操作。并在最后的预测时，使用全局平均池化和全连接层来输出可能的类别数，并使用Softmax获得最有可能的预测类别。</p>
</br>

<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h3><p>该论文提出了一种结合了CNN和Transformer优势的混合模型TransCNN，并且提出了一个层级多头注意力机制模块（H-MHSA)用于减少原始Transformer中计算注意力机制导致的空间复杂度过高的问题。该模型在多个数据集上进行测试，获得了很好的实验结果。</p>
</div><div class="post-copyright"><blockquote><p>原文作者: zhahoi</p><p>原文链接: <a href="https://zhahoi.github.io/posts/9756efb3.html">https://zhahoi.github.io/posts/9756efb3.html</a></p><p>版权声明: 转载请注明出处(必须保留原文作者署名原文链接)</p></blockquote></div><div class="tags"><a href="/tags/Transformer-CNN/">Transformer CNN</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/posts/54abec2e.html" class="next">使用Git上传代码到Github</a></div><div id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC80OTA0MS8yNTUzNg=="></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%96%87%E7%8C%AE%E5%87%BA%E5%A4%84"><span class="toc-number">1.</span> <span class="toc-text">1.文献出处</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%96%87%E7%8C%AE%E7%A0%94%E7%A9%B6%E5%86%85%E5%AE%B9"><span class="toc-number">2.</span> <span class="toc-text">2.文献研究内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%A0%94%E7%A9%B6%E5%88%9B%E6%96%B0%E7%82%B9"><span class="toc-number">3.</span> <span class="toc-text">3.研究创新点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E7%A0%94%E7%A9%B6%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%96%B9%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">4.研究思路与方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">5.总结</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/posts/9756efb3.html">Transformer in Convolutional Neural Networks论文阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/54abec2e.html">使用Git上传代码到Github</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/4a17b156.html">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/">常用指令</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/Transformer-CNN/" style="font-size: 15px;">Transformer CNN</a> <a href="/tags/git/" style="font-size: 15px;">git</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a><span class="archive-list-count">3</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://www.pyimagesearch.com/" title="pyimagesearch" target="_blank">pyimagesearch</a><ul></ul><a href="https://blog.floydhub.com/" title="floydhub's blog" target="_blank">floydhub's blog</a><ul></ul><a href="https://keras-cn.readthedocs.io/" title="Keras中文文档" target="_blank">Keras中文文档</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">zhahoi.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a target="_blank" rel="noopener" href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','164591113','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?b803f369eae2203f4e666f3d6f7c5e01";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML" async></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script><script>(function(d, s) {
  var j, e = d.getElementsByTagName('body')[0];
  if (typeof LivereTower === 'function') { return; }
  j = d.createElement(s);
  j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
  j.async = true;
  e.appendChild(j);
})(document, 'script');
</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/chitose.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":1}});</script></body></html>