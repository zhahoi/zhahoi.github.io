<!DOCTYPE html><html lang="zh-CN"><head><meta name="baidu-site-verification" content="h7QqekqYfg"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Every man is the master of his own fortune."><meta name="keywords" content="hayes"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="../css/style.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="../css/highlight.css?v=2.0.5"><link rel="Shortcut Icon" href="../favicon.ico"><link rel="bookmark" href="../favicon.ico"><link rel="apple-touch-icon" href="../apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="../apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="../atom.xml"><title>Transformer in Convolutional Neural Networks论文阅读笔记 | 海因斯的部落格</title><meta name="generator" content="Hexo 4.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Transformer in Convolutional Neural Networks论文阅读笔记</h1><a id="logo" href="../.">海因斯的部落格</a><p class="description">做颗星星，有棱有角，还会发光。</p></div><div id="nav-menu"><a href="../." class="current"><i class="fa fa-home"> 首页</i></a><a href="../archives/"><i class="fa fa-archive"> 归档</i></a><a href="../about/"><i class="fa fa-user"> 关于</i></a><a href="../atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Transformer in Convolutional Neural Networks论文阅读笔记</h1><div class="post-meta"><a href="#comments" class="comment-count"></a><p><span class="date">Apr 23, 2022</span><span><a href="../categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" class="category">论文阅读</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h3 id="1-文献出处"><a href="#1-文献出处" class="headerlink" title="1.文献出处"></a>1.文献出处</h3><p>文献名：<em>Transformer in Convolutional Neural Networks</em></p>
<p>论文地址:<a href="https://arxiv.org/abs/2106.03180" target="_blank" rel="noopener">https://arxiv.org/abs/2106.03180</a> </p>
<p>代码地址：<a href="https://github.com/yun-liu/TransCNN" target="_blank" rel="noopener">https://github.com/yun-liu/TransCNN</a></p>
<h3 id="2-文献研究内容"><a href="#2-文献研究内容" class="headerlink" title="2.文献研究内容"></a>2.文献研究内容</h3><p>针对多头自注意力模块（Multi-Head Self-Attention, MHSA）中计算和空间复杂度过高导致Vision Transformer效率低下的缺陷，提出一种层级多头注意力机制模块（Hierarchical Multi-Head Self-Attention, H-MHSA)，最后搭建而成的模型被称为TransCNN。</p>
<h3 id="3-研究创新点"><a href="#3-研究创新点" class="headerlink" title="3.研究创新点"></a>3.研究创新点</h3><ul>
<li><p>提出了层级多头注意力机制模块（MHSA)来使得Transformer中的自注意力机制计算得更加灵活和高效。</p>
</li>
<li><p>不再计算所有tokens的注意力，而是将patches进一步分组到小网格(grids)中，并计算每个网格中的注意力。这一步捕捉了局部关系，并产生了更具辨别力的局部表示。然后将这些小网格合并成更大的网格，并通过将前一步中的小网格视为标记来计算每个新网格中的注意力。通过这种方式，模型基本上捕获了更大区域中的特征关系。该过程被迭代以逐渐减少tokens的数量。</p>
</li>
<li><p>在整个过程中，H-MHSA模块逐步计算不断增加的区域大小中的自注意力，并自然地以分层方式对全局关系进行建模。 由于每一步的每个网格只有少量的tokens，可以显着降低视觉变换器的计算&#x2F;空间复杂度。</p>
</li>
<li><p>与之前对序列数据进行操作的Transformer网络不同，TransCNN 直接处理 3D 特征图，因此与过去十年提出的先进 CNN 技术兼容。 TransCNN 本质上继承了 CNN 和Transformer的优点，因此在学习尺度&#x2F;移位不变的特征表示和对输入数据中的长期依赖建模方面表现良好。</p>
</li>
</ul>
<h3 id="4-研究思路与方法"><a href="#4-研究思路与方法" class="headerlink" title="4.研究思路与方法"></a>4.研究思路与方法</h3><p><a href="https://imgtu.com/i/Lf0PXT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2022/04/23/Lf0PXT.md.png" alt="Lf0PXT.md.png"></a></p>
<p>提出的TransCNN模型是由层级多头注意力机制模块（H-MHSA)、反向残差瓶颈模块（IRB)和双分支下采样模块（TDB)共同组成的。</p>
</div><div class="post-copyright"><blockquote><p>原文作者: zhahoi</p><p>原文链接: <a href="../https:/zhahoi.github.io/posts/9756efb3.html">https://zhahoi.github.io/posts/9756efb3.html</a></p><p>版权声明: 转载请注明出处(必须保留原文作者署名原文链接)</p></blockquote></div><div class="tags"><a href="../tags/Transformer-CNN/">Transformer CNN</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="54abec2e.html" class="next">使用Git上传代码到Github</a></div><div id="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC80OTA0MS8yNTUzNg=="></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-文献出处"><span class="toc-number">1.</span> <span class="toc-text">1.文献出处</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-文献研究内容"><span class="toc-number">2.</span> <span class="toc-text">2.文献研究内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-研究创新点"><span class="toc-number">3.</span> <span class="toc-text">3.研究创新点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-研究思路与方法"><span class="toc-number">4.</span> <span class="toc-text">4.研究思路与方法</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="">Transformer in Convolutional Neural Networks论文阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="54abec2e.html">使用Git上传代码到Github</a></li><li class="post-list-item"><a class="post-list-link" href="4a17b156.html">Hello World</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../categories/%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/">常用指令</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="../categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="../tags/Transformer-CNN/" style="font-size: 15px;">Transformer CNN</a> <a href="../tags/git/" style="font-size: 15px;">git</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="../archives/2022/">2022</a><span class="archive-list-count">3</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://www.pyimagesearch.com/" title="pyimagesearch" target="_blank">pyimagesearch</a><ul></ul><a href="https://blog.floydhub.com/" title="floydhub's blog" target="_blank">floydhub's blog</a><ul></ul><a href="https://keras-cn.readthedocs.io/" title="Keras中文文档" target="_blank">Keras中文文档</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="../." rel="nofollow">zhahoi.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','164591113','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?b803f369eae2203f4e666f3d6f7c5e01";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="../js/search.json.js?v=2.0.5"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});</script><script type="text/javascript" src="../cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML" async></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="../js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="../js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="../share/css/share.css"><script type="text/javascript" src="../share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="../share/js/qrcode.js" charset="utf-8"></script><script>(function(d, s) {
  var j, e = d.getElementsByTagName('body')[0];
  if (typeof LivereTower === 'function') { return; }
  j = d.createElement(s);
  j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
  j.async = true;
  e.appendChild(j);
})(document, 'script');
</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/chitose.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":1}});</script></body></html>